// Code generated by command: go run gen.go -out seqdec_amd64.s -stubs delme.go -pkg=zstd. DO NOT EDIT.

//go:build !appengine && !noasm && gc && !noasm
// +build !appengine,!noasm,gc,!noasm

// func sequenceDecs_decodeSync_amd64(s *sequenceDecs, br *bitReader, ctx *decodeSyncAsmContext) int
// Requires: CMOV, SSE
TEXT Â·sequenceDecs_decodeSync_amd64(SB), $64-32
	MOVQ    br+8(FP), AX
	MOVQ    32(AX), DX
	MOVBQZX 40(AX), BX
	MOVQ    24(AX), SI
	MOVQ    (AX), AX
	ADDQ    SI, AX
	MOVQ    AX, (SP)
	MOVQ    ctx+16(FP), AX
	MOVQ    72(AX), DI
	MOVQ    80(AX), R8
	MOVQ    88(AX), R9
	MOVQ    112(AX), R10
	MOVQ    144(AX), R11
	MOVQ    136(AX), R12
	MOVQ    200(AX), CX
	MOVQ    CX, 56(SP)
	MOVQ    176(AX), CX
	MOVQ    CX, 48(SP)
	MOVQ    184(AX), CX
	MOVQ    CX, 40(SP)
	MOVQ    40(SP), CX
	ADDQ    CX, 48(SP)

	// outBase += outPosition
	ADDQ R12, R10
	MOVQ 128(AX), CX
	MOVQ CX, 32(SP)

	// Check if we're retrying after `out` resize
	CMPQ 208(AX), $0x01
	JNE  sequenceDecs_decodeSync_amd64_main_loop
	MOVQ 216(AX), CX
	MOVQ CX, 24(SP)
	MOVQ 232(AX), CX
	MOVQ CX, 8(SP)
	MOVQ 224(AX), AX
	MOVQ AX, 16(SP)
	JMP  execute_single_triple
	MOVQ s+0(FP), AX

sequenceDecs_decodeSync_amd64_main_loop:
	MOVQ (SP), R13

	// Fill bitreader to have enough for the offset and match length.
	CMPQ SI, $0x08
	JL   sequenceDecs_decodeSync_amd64_fill_byte_by_byte
	MOVQ BX, AX
	SHRQ $0x03, AX
	SUBQ AX, R13
	MOVQ (R13), DX
	SUBQ AX, SI
	ANDQ $0x07, BX
	JMP  sequenceDecs_decodeSync_amd64_fill_end

sequenceDecs_decodeSync_amd64_fill_byte_by_byte:
	CMPQ    SI, $0x00
	JLE     sequenceDecs_decodeSync_amd64_fill_end
	CMPQ    BX, $0x07
	JLE     sequenceDecs_decodeSync_amd64_fill_end
	SHLQ    $0x08, DX
	SUBQ    $0x01, R13
	SUBQ    $0x01, SI
	SUBQ    $0x08, BX
	MOVBQZX (R13), AX
	ORQ     AX, DX
	JMP     sequenceDecs_decodeSync_amd64_fill_byte_by_byte

sequenceDecs_decodeSync_amd64_fill_end:
	// Update offset
	MOVQ    R9, AX
	MOVQ    BX, CX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R14
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R14
	ADDQ    R14, AX
	MOVQ    AX, 8(SP)

	// Update match length
	MOVQ    R8, AX
	MOVQ    BX, CX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R14
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R14
	ADDQ    R14, AX
	MOVQ    AX, 16(SP)

	// Fill bitreader to have enough for the remaining
	CMPQ SI, $0x08
	JL   sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte
	MOVQ BX, AX
	SHRQ $0x03, AX
	SUBQ AX, R13
	MOVQ (R13), DX
	SUBQ AX, SI
	ANDQ $0x07, BX
	JMP  sequenceDecs_decodeSync_amd64_fill_2_end

sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte:
	CMPQ    SI, $0x00
	JLE     sequenceDecs_decodeSync_amd64_fill_2_end
	CMPQ    BX, $0x07
	JLE     sequenceDecs_decodeSync_amd64_fill_2_end
	SHLQ    $0x08, DX
	SUBQ    $0x01, R13
	SUBQ    $0x01, SI
	SUBQ    $0x08, BX
	MOVBQZX (R13), AX
	ORQ     AX, DX
	JMP     sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte

sequenceDecs_decodeSync_amd64_fill_2_end:
	// Update literal length
	MOVQ    DI, AX
	MOVQ    BX, CX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R14
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R14
	ADDQ    R14, AX
	MOVQ    AX, 24(SP)

	// Fill bitreader for state updates
	MOVQ    R13, (SP)
	MOVQ    R9, AX
	SHRQ    $0x08, AX
	MOVBQZX AL, AX
	MOVQ    ctx+16(FP), CX
	CMPQ    96(CX), $0x00
	JZ      sequenceDecs_decodeSync_amd64_skip_update

	// Update Literal Length State
	MOVBQZX DI, R13
	SHRQ    $0x10, DI
	MOVWQZX DI, DI
	CMPQ    R13, $0x00
	JZ      sequenceDecs_decodeSync_amd64_llState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R13, BX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVQ    R13, CX
	NEGQ    CX
	SHRQ    CL, R14
	ADDQ    R14, DI

sequenceDecs_decodeSync_amd64_llState_updateState_skip_zero:
	// Load ctx.llTable
	MOVQ ctx+16(FP), CX
	MOVQ (CX), CX
	MOVQ (CX)(DI*8), DI

	// Update Match Length State
	MOVBQZX R8, R13
	SHRQ    $0x10, R8
	MOVWQZX R8, R8
	CMPQ    R13, $0x00
	JZ      sequenceDecs_decodeSync_amd64_mlState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R13, BX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVQ    R13, CX
	NEGQ    CX
	SHRQ    CL, R14
	ADDQ    R14, R8

sequenceDecs_decodeSync_amd64_mlState_updateState_skip_zero:
	// Load ctx.mlTable
	MOVQ ctx+16(FP), CX
	MOVQ 24(CX), CX
	MOVQ (CX)(R8*8), R8

	// Update Offset State
	MOVBQZX R9, R13
	SHRQ    $0x10, R9
	MOVWQZX R9, R9
	CMPQ    R13, $0x00
	JZ      sequenceDecs_decodeSync_amd64_ofState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R13, BX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVQ    R13, CX
	NEGQ    CX
	SHRQ    CL, R14
	ADDQ    R14, R9

sequenceDecs_decodeSync_amd64_ofState_updateState_skip_zero:
	// Load ctx.ofTable
	MOVQ ctx+16(FP), CX
	MOVQ 48(CX), CX
	MOVQ (CX)(R9*8), R9

sequenceDecs_decodeSync_amd64_skip_update:
	// Adjust offset
	MOVQ   s+0(FP), CX
	MOVQ   8(SP), R13
	CMPQ   AX, $0x01
	JBE    sequenceDecs_decodeSync_amd64_adjust_offsetB_1_or_0
	MOVUPS 144(CX), X0
	MOVQ   R13, 144(CX)
	MOVUPS X0, 152(CX)
	JMP    sequenceDecs_decodeSync_amd64_adjust_end

sequenceDecs_decodeSync_amd64_adjust_offsetB_1_or_0:
	CMPQ 24(SP), $0x00000000
	JNE  sequenceDecs_decodeSync_amd64_adjust_offset_maybezero
	INCQ R13
	JMP  sequenceDecs_decodeSync_amd64_adjust_offset_nonzero

sequenceDecs_decodeSync_amd64_adjust_offset_maybezero:
	TESTQ R13, R13
	JNZ   sequenceDecs_decodeSync_amd64_adjust_offset_nonzero
	MOVQ  144(CX), R13
	JMP   sequenceDecs_decodeSync_amd64_adjust_end

sequenceDecs_decodeSync_amd64_adjust_offset_nonzero:
	MOVQ    R13, AX
	XORQ    R14, R14
	MOVQ    $-1, BP
	CMPQ    R13, $0x03
	CMOVQEQ R14, AX
	CMOVQEQ BP, R14
	LEAQ    144(CX), BP
	ADDQ    (BP)(AX*8), R14
	JNZ     sequenceDecs_decodeSync_amd64_adjust_temp_valid
	MOVQ    $0x00000001, R14

sequenceDecs_decodeSync_amd64_adjust_temp_valid:
	CMPQ R13, $0x01
	JZ   sequenceDecs_decodeSync_amd64_adjust_skip
	MOVQ 152(CX), AX
	MOVQ AX, 160(CX)

sequenceDecs_decodeSync_amd64_adjust_skip:
	MOVQ 144(CX), AX
	MOVQ AX, 152(CX)
	MOVQ R14, 144(CX)
	MOVQ R14, R13

sequenceDecs_decodeSync_amd64_adjust_end:
	MOVQ R13, 8(SP)

	// Check values
	MOVQ  16(SP), AX
	MOVQ  24(SP), CX
	LEAQ  (AX)(CX*1), R14
	MOVQ  s+0(FP), BP
	ADDQ  R14, 256(BP)
	MOVQ  ctx+16(FP), R14
	SUBQ  CX, 104(R14)
	CMPQ  AX, $0x00020002
	JA    sequenceDecs_decodeSync_amd64_error_match_len_too_big
	TESTQ R13, R13
	JNZ   sequenceDecs_decodeSync_amd64_match_len_ofs_ok
	TESTQ AX, AX
	JNZ   sequenceDecs_decodeSync_amd64_error_match_len_ofs_mismatch

sequenceDecs_decodeSync_amd64_match_len_ofs_ok:
execute_single_triple:
	// Check if ll + ml < cap(out)
	MOVQ 32(SP), AX
	MOVQ 24(SP), CX
	ADDQ 16(SP), CX
	CMPQ CX, AX
	JA   error_out_of_capacity

	// Copy literals
	MOVQ  24(SP), AX
	TESTQ AX, AX
	JZ    check_offset
	XORQ  CX, CX
	TESTQ $0x00000001, AX
	JZ    copy_1_word
	MOVB  (R11)(CX*1), R13
	MOVB  R13, (R10)(CX*1)
	ADDQ  $0x01, CX

copy_1_word:
	TESTQ $0x00000002, AX
	JZ    copy_1_dword
	MOVW  (R11)(CX*1), R13
	MOVW  R13, (R10)(CX*1)
	ADDQ  $0x02, CX

copy_1_dword:
	TESTQ $0x00000004, AX
	JZ    copy_1_qword
	MOVL  (R11)(CX*1), R13
	MOVL  R13, (R10)(CX*1)
	ADDQ  $0x04, CX

copy_1_qword:
	TESTQ $0x00000008, AX
	JZ    copy_1_test
	MOVQ  (R11)(CX*1), R13
	MOVQ  R13, (R10)(CX*1)
	ADDQ  $0x08, CX
	JMP   copy_1_test

copy_1:
	MOVUPS (R11)(CX*1), X0
	MOVUPS X0, (R10)(CX*1)
	ADDQ   $0x10, CX

copy_1_test:
	CMPQ CX, AX
	JB   copy_1
	ADDQ AX, R11
	ADDQ AX, R10
	ADDQ AX, R12
	MOVQ 8(SP), R15

	// Malformed input if seq.mo > t+len(hist) || seq.mo > s.windowSize)
check_offset:
	MOVQ R12, AX
	ADDQ 40(SP), AX
	CMPQ R15, AX
	JG   error_match_off_too_big
	CMPQ R15, 56(SP)
	JG   error_match_off_too_big
	MOVQ 16(SP), AX

	// Copy match from history
	MOVQ  R15, CX
	SUBQ  R12, CX
	JLS   copy_match
	MOVQ  48(SP), R13
	SUBQ  CX, R13
	CMPQ  AX, CX
	JGE   copy_all_from_history
	XORQ  CX, CX
	TESTQ $0x00000001, AX
	JZ    copy_4_word
	MOVB  (R13)(CX*1), R14
	MOVB  R14, (R10)(CX*1)
	ADDQ  $0x01, CX

copy_4_word:
	TESTQ $0x00000002, AX
	JZ    copy_4_dword
	MOVW  (R13)(CX*1), R14
	MOVW  R14, (R10)(CX*1)
	ADDQ  $0x02, CX

copy_4_dword:
	TESTQ $0x00000004, AX
	JZ    copy_4_qword
	MOVL  (R13)(CX*1), R14
	MOVL  R14, (R10)(CX*1)
	ADDQ  $0x04, CX

copy_4_qword:
	TESTQ $0x00000008, AX
	JZ    copy_4_test
	MOVQ  (R13)(CX*1), R14
	MOVQ  R14, (R10)(CX*1)
	ADDQ  $0x08, CX
	JMP   copy_4_test

copy_4:
	MOVUPS (R13)(CX*1), X0
	MOVUPS X0, (R10)(CX*1)
	ADDQ   $0x10, CX

copy_4_test:
	CMPQ CX, AX
	JB   copy_4
	ADDQ AX, R12
	ADDQ AX, R10
	JMP  handle_loop
	JMP loop_finished

copy_all_from_history:
	XORQ  R14, R14
	TESTQ $0x00000001, CX
	JZ    copy_5_word
	MOVB  (R13)(R14*1), BP
	MOVB  BP, (R10)(R14*1)
	ADDQ  $0x01, R14

copy_5_word:
	TESTQ $0x00000002, CX
	JZ    copy_5_dword
	MOVW  (R13)(R14*1), BP
	MOVW  BP, (R10)(R14*1)
	ADDQ  $0x02, R14

copy_5_dword:
	TESTQ $0x00000004, CX
	JZ    copy_5_qword
	MOVL  (R13)(R14*1), BP
	MOVL  BP, (R10)(R14*1)
	ADDQ  $0x04, R14

copy_5_qword:
	TESTQ $0x00000008, CX
	JZ    copy_5_test
	MOVQ  (R13)(R14*1), BP
	MOVQ  BP, (R10)(R14*1)
	ADDQ  $0x08, R14
	JMP   copy_5_test

copy_5:
	MOVUPS (R13)(R14*1), X0
	MOVUPS X0, (R10)(R14*1)
	ADDQ   $0x10, R14

copy_5_test:
	CMPQ R14, CX
	JB   copy_5
	ADDQ CX, R10
	ADDQ CX, R12
	SUBQ CX, AX

	// Copy match from the current buffer
copy_match:
	TESTQ AX, AX
	JZ    handle_loop
	MOVQ  R10, CX
	SUBQ  R15, CX

	// ml <= mo
	CMPQ AX, R15
	JA   copy_overlapping_match

	// Copy non-overlapping match
	XORQ R13, R13

copy_2:
	MOVUPS (CX)(R13*1), X0
	MOVUPS X0, (R10)(R13*1)
	ADDQ   $0x10, R13
	CMPQ   R13, AX
	JB     copy_2
	ADDQ   AX, R10
	ADDQ   AX, R12
	JMP    handle_loop

	// Copy overlapping match
copy_overlapping_match:
	XORQ R13, R13

copy_slow_3:
	MOVB (CX)(R13*1), R14
	MOVB R14, (R10)(R13*1)
	INCQ R13
	CMPQ R13, AX
	JB   copy_slow_3
	ADDQ AX, R10
	ADDQ AX, R12

handle_loop:
	MOVQ ctx+16(FP), AX
	DECQ 96(AX)
	JNS  sequenceDecs_decodeSync_amd64_main_loop

loop_finished:
	MOVQ s+0(FP), AX
	MOVQ br+8(FP), AX
	MOVQ DX, 32(AX)
	MOVB BL, 40(AX)
	MOVQ SI, 24(AX)

	// Return success
	MOVQ $0x00000000, ret+24(FP)
	RET

	// Return with match length error
sequenceDecs_decodeSync_amd64_error_match_len_ofs_mismatch:
	MOVQ 16(SP), AX
	MOVQ ctx+16(FP), CX
	MOVQ AX, 224(CX)
	MOVQ $0x00000001, ret+24(FP)
	RET

	// Return with match too long error
sequenceDecs_decodeSync_amd64_error_match_len_too_big:
	MOVQ 16(SP), AX
	MOVQ ctx+16(FP), CX
	MOVQ AX, 224(CX)
	MOVQ $0x00000002, ret+24(FP)
	RET

	// Return with match offset too long error
error_match_off_too_big:
	MOVQ ctx+16(FP), AX
	MOVQ 8(SP), CX
	MOVQ CX, 232(AX)
	MOVQ R12, 136(AX)
	MOVQ $0x00000003, ret+24(FP)
	RET

	// Return request to resize `out` by at least ll + ml bytes
error_out_of_capacity:
	MOVQ ctx+16(FP), AX
	MOVQ 24(SP), CX
	MOVQ CX, 216(AX)
	MOVQ 16(SP), CX
	MOVQ CX, 224(AX)
	MOVQ R12, 136(AX)
	MOVQ br+8(FP), AX
	MOVQ DX, 32(AX)
	MOVB BL, 40(AX)
	MOVQ SI, 24(AX)
	MOVQ $0x00000004, ret+24(FP)
	RET
