// Code generated by command: go run gen.go -out seqdec_amd64.s -stubs delme.go -pkg=zstd. DO NOT EDIT.

//go:build !appengine && !noasm && gc && !noasm
// +build !appengine,!noasm,gc,!noasm

// func sequenceDecs_decodeSync_amd64(s *sequenceDecs, br *bitReader, ctx *decodeSyncAsmContext) int
// Requires: CMOV, SSE
TEXT Â·sequenceDecs_decodeSync_amd64(SB), $72-32
	MOVQ    br+8(FP), AX
	MOVQ    32(AX), DX
	MOVBQZX 40(AX), BX
	MOVQ    24(AX), SI
	MOVQ    (AX), AX
	ADDQ    SI, AX
	MOVQ    AX, (SP)
	MOVQ    ctx+16(FP), AX
	MOVQ    72(AX), DI
	MOVQ    80(AX), R8
	MOVQ    88(AX), R9
	MOVQ    112(AX), R10
	MOVQ    144(AX), CX
	MOVQ    CX, 40(SP)
	MOVQ    136(AX), R11
	MOVQ    200(AX), CX
	MOVQ    CX, 64(SP)
	MOVQ    176(AX), CX
	MOVQ    CX, 56(SP)
	MOVQ    184(AX), CX
	MOVQ    CX, 48(SP)
	MOVQ    48(SP), CX
	ADDQ    CX, 56(SP)

	// outBase += outPosition
	ADDQ R11, R10
	MOVQ 128(AX), CX
	MOVQ CX, 32(SP)

	// Check if we're retrying after `out` resize
	CMPQ 208(AX), $0x01
	JNE  sequenceDecs_decodeSync_amd64_main_loop
	MOVQ 216(AX), CX
	MOVQ CX, 24(SP)
	MOVQ 232(AX), CX
	MOVQ CX, 8(SP)
	MOVQ 224(AX), AX
	MOVQ AX, 16(SP)
	JMP  execute_single_triple
	MOVQ s+0(FP), AX

sequenceDecs_decodeSync_amd64_main_loop:
	MOVQ (SP), R12

	// Fill bitreader to have enough for the offset and match length.
	CMPQ SI, $0x08
	JL   sequenceDecs_decodeSync_amd64_fill_byte_by_byte
	MOVQ BX, AX
	SHRQ $0x03, AX
	SUBQ AX, R12
	MOVQ (R12), DX
	SUBQ AX, SI
	ANDQ $0x07, BX
	JMP  sequenceDecs_decodeSync_amd64_fill_end

sequenceDecs_decodeSync_amd64_fill_byte_by_byte:
	CMPQ    SI, $0x00
	JLE     sequenceDecs_decodeSync_amd64_fill_end
	CMPQ    BX, $0x07
	JLE     sequenceDecs_decodeSync_amd64_fill_end
	SHLQ    $0x08, DX
	SUBQ    $0x01, R12
	SUBQ    $0x01, SI
	SUBQ    $0x08, BX
	MOVBQZX (R12), AX
	ORQ     AX, DX
	JMP     sequenceDecs_decodeSync_amd64_fill_byte_by_byte

sequenceDecs_decodeSync_amd64_fill_end:
	// Update offset
	MOVQ    R9, AX
	MOVQ    BX, CX
	MOVQ    DX, R13
	SHLQ    CL, R13
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R13
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R13
	ADDQ    R13, AX
	MOVQ    AX, 8(SP)

	// Update match length
	MOVQ    R8, AX
	MOVQ    BX, CX
	MOVQ    DX, R13
	SHLQ    CL, R13
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R13
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R13
	ADDQ    R13, AX
	MOVQ    AX, 16(SP)

	// Fill bitreader to have enough for the remaining
	CMPQ SI, $0x08
	JL   sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte
	MOVQ BX, AX
	SHRQ $0x03, AX
	SUBQ AX, R12
	MOVQ (R12), DX
	SUBQ AX, SI
	ANDQ $0x07, BX
	JMP  sequenceDecs_decodeSync_amd64_fill_2_end

sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte:
	CMPQ    SI, $0x00
	JLE     sequenceDecs_decodeSync_amd64_fill_2_end
	CMPQ    BX, $0x07
	JLE     sequenceDecs_decodeSync_amd64_fill_2_end
	SHLQ    $0x08, DX
	SUBQ    $0x01, R12
	SUBQ    $0x01, SI
	SUBQ    $0x08, BX
	MOVBQZX (R12), AX
	ORQ     AX, DX
	JMP     sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte

sequenceDecs_decodeSync_amd64_fill_2_end:
	// Update literal length
	MOVQ    DI, AX
	MOVQ    BX, CX
	MOVQ    DX, R13
	SHLQ    CL, R13
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R13
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R13
	ADDQ    R13, AX
	MOVQ    AX, 24(SP)

	// Fill bitreader for state updates
	MOVQ    R12, (SP)
	MOVQ    R9, AX
	SHRQ    $0x08, AX
	MOVBQZX AL, AX
	MOVQ    ctx+16(FP), CX
	CMPQ    96(CX), $0x00
	JZ      sequenceDecs_decodeSync_amd64_skip_update

	// Update Literal Length State
	MOVBQZX DI, R12
	SHRQ    $0x10, DI
	MOVWQZX DI, DI
	CMPQ    R12, $0x00
	JZ      sequenceDecs_decodeSync_amd64_llState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R12, BX
	MOVQ    DX, R13
	SHLQ    CL, R13
	MOVQ    R12, CX
	NEGQ    CX
	SHRQ    CL, R13
	ADDQ    R13, DI

sequenceDecs_decodeSync_amd64_llState_updateState_skip_zero:
	// Load ctx.llTable
	MOVQ ctx+16(FP), CX
	MOVQ (CX), CX
	MOVQ (CX)(DI*8), DI

	// Update Match Length State
	MOVBQZX R8, R12
	SHRQ    $0x10, R8
	MOVWQZX R8, R8
	CMPQ    R12, $0x00
	JZ      sequenceDecs_decodeSync_amd64_mlState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R12, BX
	MOVQ    DX, R13
	SHLQ    CL, R13
	MOVQ    R12, CX
	NEGQ    CX
	SHRQ    CL, R13
	ADDQ    R13, R8

sequenceDecs_decodeSync_amd64_mlState_updateState_skip_zero:
	// Load ctx.mlTable
	MOVQ ctx+16(FP), CX
	MOVQ 24(CX), CX
	MOVQ (CX)(R8*8), R8

	// Update Offset State
	MOVBQZX R9, R12
	SHRQ    $0x10, R9
	MOVWQZX R9, R9
	CMPQ    R12, $0x00
	JZ      sequenceDecs_decodeSync_amd64_ofState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R12, BX
	MOVQ    DX, R13
	SHLQ    CL, R13
	MOVQ    R12, CX
	NEGQ    CX
	SHRQ    CL, R13
	ADDQ    R13, R9

sequenceDecs_decodeSync_amd64_ofState_updateState_skip_zero:
	// Load ctx.ofTable
	MOVQ ctx+16(FP), CX
	MOVQ 48(CX), CX
	MOVQ (CX)(R9*8), R9

sequenceDecs_decodeSync_amd64_skip_update:
	// Adjust offset
	MOVQ   s+0(FP), CX
	MOVQ   8(SP), R12
	CMPQ   AX, $0x01
	JBE    sequenceDecs_decodeSync_amd64_adjust_offsetB_1_or_0
	MOVUPS 144(CX), X0
	MOVQ   R12, 144(CX)
	MOVUPS X0, 152(CX)
	JMP    sequenceDecs_decodeSync_amd64_adjust_end

sequenceDecs_decodeSync_amd64_adjust_offsetB_1_or_0:
	CMPQ 24(SP), $0x00000000
	JNE  sequenceDecs_decodeSync_amd64_adjust_offset_maybezero
	INCQ R12
	JMP  sequenceDecs_decodeSync_amd64_adjust_offset_nonzero

sequenceDecs_decodeSync_amd64_adjust_offset_maybezero:
	TESTQ R12, R12
	JNZ   sequenceDecs_decodeSync_amd64_adjust_offset_nonzero
	MOVQ  144(CX), R12
	JMP   sequenceDecs_decodeSync_amd64_adjust_end

sequenceDecs_decodeSync_amd64_adjust_offset_nonzero:
	MOVQ    R12, AX
	XORQ    R13, R13
	MOVQ    $-1, R15
	CMPQ    R12, $0x03
	CMOVQEQ R13, AX
	CMOVQEQ R15, R13
	LEAQ    144(CX), R15
	ADDQ    (R15)(AX*8), R13
	JNZ     sequenceDecs_decodeSync_amd64_adjust_temp_valid
	MOVQ    $0x00000001, R13

sequenceDecs_decodeSync_amd64_adjust_temp_valid:
	CMPQ R12, $0x01
	JZ   sequenceDecs_decodeSync_amd64_adjust_skip
	MOVQ 152(CX), AX
	MOVQ AX, 160(CX)

sequenceDecs_decodeSync_amd64_adjust_skip:
	MOVQ 144(CX), AX
	MOVQ AX, 152(CX)
	MOVQ R13, 144(CX)
	MOVQ R13, R12

sequenceDecs_decodeSync_amd64_adjust_end:
	MOVQ R12, 8(SP)

	// Check values
	MOVQ  16(SP), AX
	MOVQ  24(SP), CX
	LEAQ  (AX)(CX*1), R13
	MOVQ  s+0(FP), R15
	ADDQ  R13, 256(R15)
	MOVQ  ctx+16(FP), R13
	SUBQ  CX, 104(R13)
	CMPQ  AX, $0x00020002
	JA    sequenceDecs_decodeSync_amd64_error_match_len_too_big
	TESTQ R12, R12
	JNZ   sequenceDecs_decodeSync_amd64_match_len_ofs_ok
	TESTQ AX, AX
	JNZ   sequenceDecs_decodeSync_amd64_error_match_len_ofs_mismatch

sequenceDecs_decodeSync_amd64_match_len_ofs_ok:
execute_single_triple:
	// Check if ll + ml < cap(out)
	MOVQ 32(SP), AX
	MOVQ 24(SP), CX
	ADDQ 16(SP), CX
	CMPQ CX, AX
	JA   error_out_of_capacity

	// Copy literals
	MOVQ  24(SP), AX
	TESTQ AX, AX
	JZ    check_offset
	MOVQ  40(SP), CX
	XORQ  R12, R12
	TESTQ $0x00000001, AX
	JZ    copy_1_word
	MOVB  (CX)(R12*1), R13
	MOVB  R13, (R10)(R12*1)
	ADDQ  $0x01, R12

copy_1_word:
	TESTQ $0x00000002, AX
	JZ    copy_1_dword
	MOVW  (CX)(R12*1), R13
	MOVW  R13, (R10)(R12*1)
	ADDQ  $0x02, R12

copy_1_dword:
	TESTQ $0x00000004, AX
	JZ    copy_1_qword
	MOVL  (CX)(R12*1), R13
	MOVL  R13, (R10)(R12*1)
	ADDQ  $0x04, R12

copy_1_qword:
	TESTQ $0x00000008, AX
	JZ    copy_1_test
	MOVQ  (CX)(R12*1), R13
	MOVQ  R13, (R10)(R12*1)
	ADDQ  $0x08, R12
	JMP   copy_1_test

copy_1:
	MOVUPS (CX)(R12*1), X0
	MOVUPS X0, (R10)(R12*1)
	ADDQ   $0x10, R12

copy_1_test:
	CMPQ R12, AX
	JB   copy_1
	ADDQ AX, 40(SP)
	ADDQ AX, R10
	ADDQ AX, R11
	MOVQ 8(SP), R14

	// Malformed input if seq.mo > t+len(hist) || seq.mo > s.windowSize)
check_offset:
	MOVQ R11, AX
	ADDQ 48(SP), AX
	CMPQ R14, AX
	JG   error_match_off_too_big
	CMPQ R14, 64(SP)
	JG   error_match_off_too_big
	MOVQ 16(SP), AX

	// Copy match from history
	MOVQ  R14, CX
	SUBQ  R11, CX
	JLS   copy_match
	MOVQ  56(SP), R12
	SUBQ  CX, R12
	CMPQ  AX, CX
	JGE   copy_all_from_history
	XORQ  CX, CX
	TESTQ $0x00000001, AX
	JZ    copy_4_word
	MOVB  (R12)(CX*1), R13
	MOVB  R13, (R10)(CX*1)
	ADDQ  $0x01, CX

copy_4_word:
	TESTQ $0x00000002, AX
	JZ    copy_4_dword
	MOVW  (R12)(CX*1), R13
	MOVW  R13, (R10)(CX*1)
	ADDQ  $0x02, CX

copy_4_dword:
	TESTQ $0x00000004, AX
	JZ    copy_4_qword
	MOVL  (R12)(CX*1), R13
	MOVL  R13, (R10)(CX*1)
	ADDQ  $0x04, CX

copy_4_qword:
	TESTQ $0x00000008, AX
	JZ    copy_4_test
	MOVQ  (R12)(CX*1), R13
	MOVQ  R13, (R10)(CX*1)
	ADDQ  $0x08, CX
	JMP   copy_4_test

copy_4:
	MOVUPS (R12)(CX*1), X0
	MOVUPS X0, (R10)(CX*1)
	ADDQ   $0x10, CX

copy_4_test:
	CMPQ CX, AX
	JB   copy_4
	ADDQ AX, R11
	ADDQ AX, R10
	JMP  handle_loop
	JMP loop_finished

copy_all_from_history:
	XORQ  R13, R13
	TESTQ $0x00000001, CX
	JZ    copy_5_word
	MOVB  (R12)(R13*1), R15
	MOVB  R15, (R10)(R13*1)
	ADDQ  $0x01, R13

copy_5_word:
	TESTQ $0x00000002, CX
	JZ    copy_5_dword
	MOVW  (R12)(R13*1), R15
	MOVW  R15, (R10)(R13*1)
	ADDQ  $0x02, R13

copy_5_dword:
	TESTQ $0x00000004, CX
	JZ    copy_5_qword
	MOVL  (R12)(R13*1), R15
	MOVL  R15, (R10)(R13*1)
	ADDQ  $0x04, R13

copy_5_qword:
	TESTQ $0x00000008, CX
	JZ    copy_5_test
	MOVQ  (R12)(R13*1), R15
	MOVQ  R15, (R10)(R13*1)
	ADDQ  $0x08, R13
	JMP   copy_5_test

copy_5:
	MOVUPS (R12)(R13*1), X0
	MOVUPS X0, (R10)(R13*1)
	ADDQ   $0x10, R13

copy_5_test:
	CMPQ R13, CX
	JB   copy_5
	ADDQ CX, R10
	ADDQ CX, R11
	SUBQ CX, AX

	// Copy match from the current buffer
copy_match:
	TESTQ AX, AX
	JZ    handle_loop
	MOVQ  R10, CX
	SUBQ  R14, CX

	// ml <= mo
	CMPQ AX, R14
	JA   copy_overlapping_match

	// Copy non-overlapping match
	XORQ R12, R12

copy_2:
	MOVUPS (CX)(R12*1), X0
	MOVUPS X0, (R10)(R12*1)
	ADDQ   $0x10, R12
	CMPQ   R12, AX
	JB     copy_2
	ADDQ   AX, R10
	ADDQ   AX, R11
	JMP    handle_loop

	// Copy overlapping match
copy_overlapping_match:
	XORQ R12, R12

copy_slow_3:
	MOVB (CX)(R12*1), R13
	MOVB R13, (R10)(R12*1)
	INCQ R12
	CMPQ R12, AX
	JB   copy_slow_3
	ADDQ AX, R10
	ADDQ AX, R11

handle_loop:
	MOVQ ctx+16(FP), AX
	DECQ 96(AX)
	JNS  sequenceDecs_decodeSync_amd64_main_loop

loop_finished:
	MOVQ s+0(FP), AX
	MOVQ br+8(FP), AX
	MOVQ DX, 32(AX)
	MOVB BL, 40(AX)
	MOVQ SI, 24(AX)

	// Return success
	MOVQ $0x00000000, ret+24(FP)
	RET

	// Return with match length error
sequenceDecs_decodeSync_amd64_error_match_len_ofs_mismatch:
	MOVQ 16(SP), AX
	MOVQ ctx+16(FP), CX
	MOVQ AX, 224(CX)
	MOVQ $0x00000001, ret+24(FP)
	RET

	// Return with match too long error
sequenceDecs_decodeSync_amd64_error_match_len_too_big:
	MOVQ 16(SP), AX
	MOVQ ctx+16(FP), CX
	MOVQ AX, 224(CX)
	MOVQ $0x00000002, ret+24(FP)
	RET

	// Return with match offset too long error
error_match_off_too_big:
	MOVQ ctx+16(FP), AX
	MOVQ 8(SP), CX
	MOVQ CX, 232(AX)
	MOVQ R11, 136(AX)
	MOVQ $0x00000003, ret+24(FP)
	RET

	// Return request to resize `out` by at least ll + ml bytes
error_out_of_capacity:
	MOVQ ctx+16(FP), AX
	MOVQ 24(SP), CX
	MOVQ CX, 216(AX)
	MOVQ 16(SP), CX
	MOVQ CX, 224(AX)
	MOVQ R11, 136(AX)
	MOVQ br+8(FP), AX
	MOVQ DX, 32(AX)
	MOVB BL, 40(AX)
	MOVQ SI, 24(AX)
	MOVQ $0x00000004, ret+24(FP)
	RET
