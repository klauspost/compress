// Code generated by command: go run gen.go -out seqdec_amd64.s -stubs delme.go -pkg=zstd. DO NOT EDIT.

//go:build !appengine && !noasm && gc && !noasm
// +build !appengine,!noasm,gc,!noasm

// func sequenceDecs_decodeSync_amd64(s *sequenceDecs, br *bitReader, ctx *decodeSyncAsmContext) int
// Requires: CMOV, SSE
TEXT Â·sequenceDecs_decodeSync_amd64(SB), $88-32
	MOVQ    br+8(FP), AX
	MOVQ    32(AX), DX
	MOVBQZX 40(AX), BX
	MOVQ    24(AX), SI
	MOVQ    (AX), AX
	ADDQ    SI, AX
	MOVQ    AX, (SP)
	MOVQ    ctx+16(FP), AX
	MOVQ    72(AX), DI
	MOVQ    80(AX), R8
	MOVQ    88(AX), R9
	MOVQ    112(AX), CX
	MOVQ    CX, 40(SP)
	MOVQ    144(AX), CX
	MOVQ    CX, 48(SP)
	MOVQ    136(AX), CX
	MOVQ    CX, 56(SP)
	MOVQ    200(AX), CX
	MOVQ    CX, 80(SP)
	MOVQ    176(AX), CX
	MOVQ    CX, 72(SP)
	MOVQ    184(AX), CX
	MOVQ    CX, 64(SP)
	MOVQ    64(SP), CX
	ADDQ    CX, 72(SP)

	// outBase += outPosition
	MOVQ 56(SP), CX
	ADDQ CX, 40(SP)
	MOVQ 128(AX), CX
	MOVQ CX, 32(SP)

	// Check if we're retrying after `out` resize
	CMPQ 208(AX), $0x01
	JNE  sequenceDecs_decodeSync_amd64_main_loop
	MOVQ 216(AX), CX
	MOVQ CX, 24(SP)
	MOVQ 232(AX), CX
	MOVQ CX, 8(SP)
	MOVQ 224(AX), CX
	MOVQ CX, 16(SP)
	JMP  execute_single_triple
	MOVQ s+0(FP), AX
	MOVQ 144(AX), R10
	MOVQ 152(AX), R11
	MOVQ 160(AX), R12

sequenceDecs_decodeSync_amd64_main_loop:
	MOVQ (SP), R13

	// Fill bitreader to have enough for the offset and match length.
	CMPQ SI, $0x08
	JL   sequenceDecs_decodeSync_amd64_fill_byte_by_byte
	MOVQ BX, AX
	SHRQ $0x03, AX
	SUBQ AX, R13
	MOVQ (R13), DX
	SUBQ AX, SI
	ANDQ $0x07, BX
	JMP  sequenceDecs_decodeSync_amd64_fill_end

sequenceDecs_decodeSync_amd64_fill_byte_by_byte:
	CMPQ    SI, $0x00
	JLE     sequenceDecs_decodeSync_amd64_fill_end
	CMPQ    BX, $0x07
	JLE     sequenceDecs_decodeSync_amd64_fill_end
	SHLQ    $0x08, DX
	SUBQ    $0x01, R13
	SUBQ    $0x01, SI
	SUBQ    $0x08, BX
	MOVBQZX (R13), AX
	ORQ     AX, DX
	JMP     sequenceDecs_decodeSync_amd64_fill_byte_by_byte

sequenceDecs_decodeSync_amd64_fill_end:
	// Update offset
	MOVQ    R9, AX
	MOVQ    BX, CX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R14
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R14
	ADDQ    R14, AX
	MOVQ    AX, 8(SP)

	// Update match length
	MOVQ    R8, AX
	MOVQ    BX, CX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R14
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R14
	ADDQ    R14, AX
	MOVQ    AX, 16(SP)

	// Fill bitreader to have enough for the remaining
	CMPQ SI, $0x08
	JL   sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte
	MOVQ BX, AX
	SHRQ $0x03, AX
	SUBQ AX, R13
	MOVQ (R13), DX
	SUBQ AX, SI
	ANDQ $0x07, BX
	JMP  sequenceDecs_decodeSync_amd64_fill_2_end

sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte:
	CMPQ    SI, $0x00
	JLE     sequenceDecs_decodeSync_amd64_fill_2_end
	CMPQ    BX, $0x07
	JLE     sequenceDecs_decodeSync_amd64_fill_2_end
	SHLQ    $0x08, DX
	SUBQ    $0x01, R13
	SUBQ    $0x01, SI
	SUBQ    $0x08, BX
	MOVBQZX (R13), AX
	ORQ     AX, DX
	JMP     sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte

sequenceDecs_decodeSync_amd64_fill_2_end:
	// Update literal length
	MOVQ    DI, AX
	MOVQ    BX, CX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R14
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R14
	ADDQ    R14, AX
	MOVQ    AX, 24(SP)

	// Fill bitreader for state updates
	MOVQ    R13, (SP)
	MOVQ    R9, AX
	SHRQ    $0x08, AX
	MOVBQZX AL, AX
	MOVQ    ctx+16(FP), CX
	CMPQ    96(CX), $0x00
	JZ      sequenceDecs_decodeSync_amd64_skip_update

	// Update Literal Length State
	MOVBQZX DI, R13
	SHRQ    $0x10, DI
	MOVWQZX DI, DI
	CMPQ    R13, $0x00
	JZ      sequenceDecs_decodeSync_amd64_llState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R13, BX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVQ    R13, CX
	NEGQ    CX
	SHRQ    CL, R14
	ADDQ    R14, DI

sequenceDecs_decodeSync_amd64_llState_updateState_skip_zero:
	// Load ctx.llTable
	MOVQ ctx+16(FP), CX
	MOVQ (CX), CX
	MOVQ (CX)(DI*8), DI

	// Update Match Length State
	MOVBQZX R8, R13
	SHRQ    $0x10, R8
	MOVWQZX R8, R8
	CMPQ    R13, $0x00
	JZ      sequenceDecs_decodeSync_amd64_mlState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R13, BX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVQ    R13, CX
	NEGQ    CX
	SHRQ    CL, R14
	ADDQ    R14, R8

sequenceDecs_decodeSync_amd64_mlState_updateState_skip_zero:
	// Load ctx.mlTable
	MOVQ ctx+16(FP), CX
	MOVQ 24(CX), CX
	MOVQ (CX)(R8*8), R8

	// Update Offset State
	MOVBQZX R9, R13
	SHRQ    $0x10, R9
	MOVWQZX R9, R9
	CMPQ    R13, $0x00
	JZ      sequenceDecs_decodeSync_amd64_ofState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R13, BX
	MOVQ    DX, R14
	SHLQ    CL, R14
	MOVQ    R13, CX
	NEGQ    CX
	SHRQ    CL, R14
	ADDQ    R14, R9

sequenceDecs_decodeSync_amd64_ofState_updateState_skip_zero:
	// Load ctx.ofTable
	MOVQ ctx+16(FP), CX
	MOVQ 48(CX), CX
	MOVQ (CX)(R9*8), R9

sequenceDecs_decodeSync_amd64_skip_update:
	// Adjust offset
	MOVQ 8(SP), CX
	CMPQ AX, $0x01
	JBE  sequenceDecs_decodeSync_amd64_adjust_offsetB_1_or_0
	MOVQ R11, R12
	MOVQ R10, R11
	MOVQ CX, R10
	JMP  sequenceDecs_decodeSync_amd64_adjust_end

sequenceDecs_decodeSync_amd64_adjust_offsetB_1_or_0:
	CMPQ 24(SP), $0x00000000
	JNE  sequenceDecs_decodeSync_amd64_adjust_offset_maybezero
	INCQ CX
	JMP  sequenceDecs_decodeSync_amd64_adjust_offset_nonzero

sequenceDecs_decodeSync_amd64_adjust_offset_maybezero:
	TESTQ CX, CX
	JNZ   sequenceDecs_decodeSync_amd64_adjust_offset_nonzero
	MOVQ  R10, CX
	JMP   sequenceDecs_decodeSync_amd64_adjust_end

sequenceDecs_decodeSync_amd64_adjust_offset_nonzero:
	CMPQ CX, $0x01
	JB   sequenceDecs_decodeSync_amd64_adjust_zero
	JEQ  sequenceDecs_decodeSync_amd64_adjust_one
	CMPQ CX, $0x02
	JA   sequenceDecs_decodeSync_amd64_adjust_three
	JMP  sequenceDecs_decodeSync_amd64_adjust_two

sequenceDecs_decodeSync_amd64_adjust_zero:
	MOVQ R10, AX
	JMP  sequenceDecs_decodeSync_amd64_adjust_test_temp_valid

sequenceDecs_decodeSync_amd64_adjust_one:
	MOVQ R11, AX
	JMP  sequenceDecs_decodeSync_amd64_adjust_test_temp_valid

sequenceDecs_decodeSync_amd64_adjust_two:
	MOVQ R12, AX
	JMP  sequenceDecs_decodeSync_amd64_adjust_test_temp_valid

sequenceDecs_decodeSync_amd64_adjust_three:
	LEAQ -1(R10), AX

sequenceDecs_decodeSync_amd64_adjust_test_temp_valid:
	TESTQ AX, AX
	JNZ   sequenceDecs_decodeSync_amd64_adjust_temp_valid
	MOVQ  $0x00000001, AX

sequenceDecs_decodeSync_amd64_adjust_temp_valid:
	CMPQ    CX, $0x01
	CMOVQNE R11, R12
	MOVQ    R10, R11
	MOVQ    AX, R10
	MOVQ    AX, CX

sequenceDecs_decodeSync_amd64_adjust_end:
	MOVQ CX, 8(SP)

	// Check values
	MOVQ  16(SP), AX
	MOVQ  24(SP), R13
	LEAQ  (AX)(R13*1), R14
	MOVQ  s+0(FP), BP
	ADDQ  R14, 256(BP)
	MOVQ  ctx+16(FP), R14
	SUBQ  R13, 104(R14)
	CMPQ  AX, $0x00020002
	JA    sequenceDecs_decodeSync_amd64_error_match_len_too_big
	TESTQ CX, CX
	JNZ   sequenceDecs_decodeSync_amd64_match_len_ofs_ok
	TESTQ AX, AX
	JNZ   sequenceDecs_decodeSync_amd64_error_match_len_ofs_mismatch

sequenceDecs_decodeSync_amd64_match_len_ofs_ok:
execute_single_triple:
	// Check if ll + ml < cap(out)
	MOVQ 32(SP), AX
	MOVQ 24(SP), CX
	ADDQ 16(SP), CX
	CMPQ CX, AX
	JA   error_out_of_capacity

	// Copy literals
	MOVQ  24(SP), AX
	TESTQ AX, AX
	JZ    check_offset
	MOVQ  48(SP), CX
	MOVQ  40(SP), R13
	XORQ  R14, R14
	TESTQ $0x00000001, AX
	JZ    copy_1_word
	MOVB  (CX)(R14*1), R15
	MOVB  R15, (R13)(R14*1)
	ADDQ  $0x01, R14

copy_1_word:
	TESTQ $0x00000002, AX
	JZ    copy_1_dword
	MOVW  (CX)(R14*1), R15
	MOVW  R15, (R13)(R14*1)
	ADDQ  $0x02, R14

copy_1_dword:
	TESTQ $0x00000004, AX
	JZ    copy_1_qword
	MOVL  (CX)(R14*1), R15
	MOVL  R15, (R13)(R14*1)
	ADDQ  $0x04, R14

copy_1_qword:
	TESTQ $0x00000008, AX
	JZ    copy_1_test
	MOVQ  (CX)(R14*1), R15
	MOVQ  R15, (R13)(R14*1)
	ADDQ  $0x08, R14
	JMP   copy_1_test

copy_1:
	MOVUPS (CX)(R14*1), X0
	MOVUPS X0, (R13)(R14*1)
	ADDQ   $0x10, R14

copy_1_test:
	CMPQ R14, AX
	JB   copy_1
	ADDQ AX, 48(SP)
	ADDQ AX, 40(SP)
	ADDQ AX, 56(SP)
	MOVQ 8(SP), R15

	// Malformed input if seq.mo > t+len(hist) || seq.mo > s.windowSize)
check_offset:
	MOVQ 56(SP), AX
	ADDQ 64(SP), AX
	CMPQ R15, AX
	JG   error_match_off_too_big
	CMPQ R15, 80(SP)
	JG   error_match_off_too_big
	MOVQ 16(SP), AX

	// Copy match from history
	MOVQ  R15, CX
	SUBQ  56(SP), CX
	JLS   copy_match
	MOVQ  72(SP), R13
	SUBQ  CX, R13
	CMPQ  AX, CX
	JGE   copy_all_from_history
	MOVQ  40(SP), CX
	XORQ  R14, R14
	TESTQ $0x00000001, AX
	JZ    copy_4_word
	MOVB  (R13)(R14*1), BP
	MOVB  BP, (CX)(R14*1)
	ADDQ  $0x01, R14

copy_4_word:
	TESTQ $0x00000002, AX
	JZ    copy_4_dword
	MOVW  (R13)(R14*1), BP
	MOVW  BP, (CX)(R14*1)
	ADDQ  $0x02, R14

copy_4_dword:
	TESTQ $0x00000004, AX
	JZ    copy_4_qword
	MOVL  (R13)(R14*1), BP
	MOVL  BP, (CX)(R14*1)
	ADDQ  $0x04, R14

copy_4_qword:
	TESTQ $0x00000008, AX
	JZ    copy_4_test
	MOVQ  (R13)(R14*1), BP
	MOVQ  BP, (CX)(R14*1)
	ADDQ  $0x08, R14
	JMP   copy_4_test

copy_4:
	MOVUPS (R13)(R14*1), X0
	MOVUPS X0, (CX)(R14*1)
	ADDQ   $0x10, R14

copy_4_test:
	CMPQ R14, AX
	JB   copy_4
	ADDQ AX, 56(SP)
	ADDQ AX, 40(SP)
	JMP  handle_loop
	JMP loop_finished

copy_all_from_history:
	MOVQ 40(SP), R13
	ADDQ CX, 40(SP)
	ADDQ CX, 56(SP)
	SUBQ CX, AX

	// Copy match from the current buffer
copy_match:
	TESTQ AX, AX
	JZ    handle_loop
	MOVQ  40(SP), CX
	SUBQ  R15, CX

	// ml <= mo
	CMPQ AX, R15
	JA   copy_overlapping_match

	// Copy non-overlapping match
	MOVQ 40(SP), R13
	XORQ R14, R14

copy_2:
	MOVUPS (CX)(R14*1), X0
	MOVUPS X0, (R13)(R14*1)
	ADDQ   $0x10, R14
	CMPQ   R14, AX
	JB     copy_2
	ADDQ   AX, 40(SP)
	ADDQ   AX, 56(SP)
	JMP    handle_loop

	// Copy overlapping match
copy_overlapping_match:
	MOVQ 40(SP), R13
	XORQ R14, R14

copy_slow_3:
	MOVB (CX)(R14*1), BP
	MOVB BP, (R13)(R14*1)
	INCQ R14
	CMPQ R14, AX
	JB   copy_slow_3
	ADDQ AX, 40(SP)
	ADDQ AX, 56(SP)

handle_loop:
	MOVQ ctx+16(FP), AX
	DECQ 96(AX)
	JNS  sequenceDecs_decodeSync_amd64_main_loop

loop_finished:
	MOVQ s+0(FP), AX
	MOVQ R10, 144(AX)
	MOVQ R11, 152(AX)
	MOVQ R12, 160(AX)
	MOVQ br+8(FP), AX
	MOVQ DX, 32(AX)
	MOVB BL, 40(AX)
	MOVQ SI, 24(AX)

	// Return success
	MOVQ $0x00000000, ret+24(FP)
	RET

	// Return with match length error
sequenceDecs_decodeSync_amd64_error_match_len_ofs_mismatch:
	MOVQ 16(SP), AX
	MOVQ ctx+16(FP), CX
	MOVQ AX, 224(CX)
	MOVQ $0x00000001, ret+24(FP)
	RET

	// Return with match too long error
sequenceDecs_decodeSync_amd64_error_match_len_too_big:
	MOVQ 16(SP), AX
	MOVQ ctx+16(FP), CX
	MOVQ AX, 224(CX)
	MOVQ $0x00000002, ret+24(FP)
	RET

	// Return with match offset too long error
error_match_off_too_big:
	MOVQ ctx+16(FP), AX
	MOVQ 8(SP), CX
	MOVQ CX, 232(AX)
	MOVQ 56(SP), CX
	MOVQ CX, 136(AX)
	MOVQ $0x00000003, ret+24(FP)
	RET

	// Return request to resize `out` by at least ll + ml bytes
error_out_of_capacity:
	MOVQ ctx+16(FP), AX
	MOVQ 24(SP), CX
	MOVQ CX, 216(AX)
	MOVQ 16(SP), CX
	MOVQ CX, 224(AX)
	MOVQ 56(SP), CX
	MOVQ CX, 136(AX)
	MOVQ br+8(FP), AX
	MOVQ DX, 32(AX)
	MOVB BL, 40(AX)
	MOVQ SI, 24(AX)
	MOVQ $0x00000004, ret+24(FP)
	RET
