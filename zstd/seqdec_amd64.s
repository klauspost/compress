// Code generated by command: go run gen.go -out seqdec_amd64.s -stubs delme.go -pkg=zstd. DO NOT EDIT.

//go:build !appengine && !noasm && gc && !noasm
// +build !appengine,!noasm,gc,!noasm

// func sequenceDecs_decodeSync_amd64(s *sequenceDecs, br *bitReader, ctx *decodeSyncAsmContext) int
// Requires: CMOV, SSE
TEXT Â·sequenceDecs_decodeSync_amd64(SB), $88-32
	MOVQ    br+8(FP), AX
	MOVQ    32(AX), DX
	MOVBQZX 40(AX), BX
	MOVQ    24(AX), SI
	MOVQ    (AX), AX
	ADDQ    SI, AX
	MOVQ    AX, (SP)
	MOVQ    ctx+16(FP), AX
	MOVQ    72(AX), DI
	MOVQ    80(AX), R8
	MOVQ    88(AX), R9
	MOVQ    112(AX), CX
	MOVQ    CX, 40(SP)
	MOVQ    144(AX), CX
	MOVQ    CX, 48(SP)
	MOVQ    136(AX), CX
	MOVQ    CX, 56(SP)
	MOVQ    200(AX), CX
	MOVQ    CX, 80(SP)
	MOVQ    176(AX), CX
	MOVQ    CX, 72(SP)
	MOVQ    184(AX), CX
	MOVQ    CX, 64(SP)
	MOVQ    64(SP), CX
	ADDQ    CX, 72(SP)

	// outBase += outPosition
	MOVQ 56(SP), CX
	ADDQ CX, 40(SP)
	MOVQ 128(AX), CX
	MOVQ CX, 32(SP)

	// Check if we're retrying after `out` resize
	CMPQ 208(AX), $0x01
	JNE  sequenceDecs_decodeSync_amd64_main_loop
	MOVQ 216(AX), CX
	MOVQ CX, 24(SP)
	MOVQ 232(AX), CX
	MOVQ CX, 8(SP)
	MOVQ 224(AX), AX
	MOVQ AX, 16(SP)
	JMP  execute_single_triple
	MOVQ s+0(FP), AX

sequenceDecs_decodeSync_amd64_main_loop:
	MOVQ (SP), R10

	// Fill bitreader to have enough for the offset and match length.
	CMPQ SI, $0x08
	JL   sequenceDecs_decodeSync_amd64_fill_byte_by_byte
	MOVQ BX, AX
	SHRQ $0x03, AX
	SUBQ AX, R10
	MOVQ (R10), DX
	SUBQ AX, SI
	ANDQ $0x07, BX
	JMP  sequenceDecs_decodeSync_amd64_fill_end

sequenceDecs_decodeSync_amd64_fill_byte_by_byte:
	CMPQ    SI, $0x00
	JLE     sequenceDecs_decodeSync_amd64_fill_end
	CMPQ    BX, $0x07
	JLE     sequenceDecs_decodeSync_amd64_fill_end
	SHLQ    $0x08, DX
	SUBQ    $0x01, R10
	SUBQ    $0x01, SI
	SUBQ    $0x08, BX
	MOVBQZX (R10), AX
	ORQ     AX, DX
	JMP     sequenceDecs_decodeSync_amd64_fill_byte_by_byte

sequenceDecs_decodeSync_amd64_fill_end:
	// Update offset
	MOVQ    R9, AX
	MOVQ    BX, CX
	MOVQ    DX, R11
	SHLQ    CL, R11
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R11
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R11
	ADDQ    R11, AX
	MOVQ    AX, 8(SP)

	// Update match length
	MOVQ    R8, AX
	MOVQ    BX, CX
	MOVQ    DX, R11
	SHLQ    CL, R11
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R11
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R11
	ADDQ    R11, AX
	MOVQ    AX, 16(SP)

	// Fill bitreader to have enough for the remaining
	CMPQ SI, $0x08
	JL   sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte
	MOVQ BX, AX
	SHRQ $0x03, AX
	SUBQ AX, R10
	MOVQ (R10), DX
	SUBQ AX, SI
	ANDQ $0x07, BX
	JMP  sequenceDecs_decodeSync_amd64_fill_2_end

sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte:
	CMPQ    SI, $0x00
	JLE     sequenceDecs_decodeSync_amd64_fill_2_end
	CMPQ    BX, $0x07
	JLE     sequenceDecs_decodeSync_amd64_fill_2_end
	SHLQ    $0x08, DX
	SUBQ    $0x01, R10
	SUBQ    $0x01, SI
	SUBQ    $0x08, BX
	MOVBQZX (R10), AX
	ORQ     AX, DX
	JMP     sequenceDecs_decodeSync_amd64_fill_2_byte_by_byte

sequenceDecs_decodeSync_amd64_fill_2_end:
	// Update literal length
	MOVQ    DI, AX
	MOVQ    BX, CX
	MOVQ    DX, R11
	SHLQ    CL, R11
	MOVB    AH, CL
	ADDQ    CX, BX
	NEGL    CX
	SHRQ    CL, R11
	SHRQ    $0x20, AX
	TESTQ   CX, CX
	CMOVQEQ CX, R11
	ADDQ    R11, AX
	MOVQ    AX, 24(SP)

	// Fill bitreader for state updates
	MOVQ    R10, (SP)
	MOVQ    R9, AX
	SHRQ    $0x08, AX
	MOVBQZX AL, AX
	MOVQ    ctx+16(FP), CX
	CMPQ    96(CX), $0x00
	JZ      sequenceDecs_decodeSync_amd64_skip_update

	// Update Literal Length State
	MOVBQZX DI, R10
	SHRQ    $0x10, DI
	MOVWQZX DI, DI
	CMPQ    R10, $0x00
	JZ      sequenceDecs_decodeSync_amd64_llState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R10, BX
	MOVQ    DX, R11
	SHLQ    CL, R11
	MOVQ    R10, CX
	NEGQ    CX
	SHRQ    CL, R11
	ADDQ    R11, DI

sequenceDecs_decodeSync_amd64_llState_updateState_skip_zero:
	// Load ctx.llTable
	MOVQ ctx+16(FP), CX
	MOVQ (CX), CX
	MOVQ (CX)(DI*8), DI

	// Update Match Length State
	MOVBQZX R8, R10
	SHRQ    $0x10, R8
	MOVWQZX R8, R8
	CMPQ    R10, $0x00
	JZ      sequenceDecs_decodeSync_amd64_mlState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R10, BX
	MOVQ    DX, R11
	SHLQ    CL, R11
	MOVQ    R10, CX
	NEGQ    CX
	SHRQ    CL, R11
	ADDQ    R11, R8

sequenceDecs_decodeSync_amd64_mlState_updateState_skip_zero:
	// Load ctx.mlTable
	MOVQ ctx+16(FP), CX
	MOVQ 24(CX), CX
	MOVQ (CX)(R8*8), R8

	// Update Offset State
	MOVBQZX R9, R10
	SHRQ    $0x10, R9
	MOVWQZX R9, R9
	CMPQ    R10, $0x00
	JZ      sequenceDecs_decodeSync_amd64_ofState_updateState_skip_zero
	MOVQ    BX, CX
	ADDQ    R10, BX
	MOVQ    DX, R11
	SHLQ    CL, R11
	MOVQ    R10, CX
	NEGQ    CX
	SHRQ    CL, R11
	ADDQ    R11, R9

sequenceDecs_decodeSync_amd64_ofState_updateState_skip_zero:
	// Load ctx.ofTable
	MOVQ ctx+16(FP), CX
	MOVQ 48(CX), CX
	MOVQ (CX)(R9*8), R9

sequenceDecs_decodeSync_amd64_skip_update:
	// Adjust offset
	MOVQ   s+0(FP), CX
	MOVQ   8(SP), R10
	CMPQ   AX, $0x01
	JBE    sequenceDecs_decodeSync_amd64_adjust_offsetB_1_or_0
	MOVUPS 144(CX), X0
	MOVQ   R10, 144(CX)
	MOVUPS X0, 152(CX)
	JMP    sequenceDecs_decodeSync_amd64_adjust_end

sequenceDecs_decodeSync_amd64_adjust_offsetB_1_or_0:
	CMPQ 24(SP), $0x00000000
	JNE  sequenceDecs_decodeSync_amd64_adjust_offset_maybezero
	INCQ R10
	JMP  sequenceDecs_decodeSync_amd64_adjust_offset_nonzero

sequenceDecs_decodeSync_amd64_adjust_offset_maybezero:
	TESTQ R10, R10
	JNZ   sequenceDecs_decodeSync_amd64_adjust_offset_nonzero
	MOVQ  144(CX), R10
	JMP   sequenceDecs_decodeSync_amd64_adjust_end

sequenceDecs_decodeSync_amd64_adjust_offset_nonzero:
	MOVQ    R10, AX
	XORQ    R11, R11
	MOVQ    $-1, R13
	CMPQ    R10, $0x03
	CMOVQEQ R11, AX
	CMOVQEQ R13, R11
	LEAQ    144(CX), R13
	ADDQ    (R13)(AX*8), R11
	JNZ     sequenceDecs_decodeSync_amd64_adjust_temp_valid
	MOVQ    $0x00000001, R11

sequenceDecs_decodeSync_amd64_adjust_temp_valid:
	CMPQ R10, $0x01
	JZ   sequenceDecs_decodeSync_amd64_adjust_skip
	MOVQ 152(CX), AX
	MOVQ AX, 160(CX)

sequenceDecs_decodeSync_amd64_adjust_skip:
	MOVQ 144(CX), AX
	MOVQ AX, 152(CX)
	MOVQ R11, 144(CX)
	MOVQ R11, R10

sequenceDecs_decodeSync_amd64_adjust_end:
	MOVQ R10, 8(SP)

	// Check values
	MOVQ  16(SP), AX
	MOVQ  24(SP), CX
	LEAQ  (AX)(CX*1), R11
	MOVQ  s+0(FP), R13
	ADDQ  R11, 256(R13)
	MOVQ  ctx+16(FP), R11
	SUBQ  CX, 104(R11)
	CMPQ  AX, $0x00020002
	JA    sequenceDecs_decodeSync_amd64_error_match_len_too_big
	TESTQ R10, R10
	JNZ   sequenceDecs_decodeSync_amd64_match_len_ofs_ok
	TESTQ AX, AX
	JNZ   sequenceDecs_decodeSync_amd64_error_match_len_ofs_mismatch

sequenceDecs_decodeSync_amd64_match_len_ofs_ok:
execute_single_triple:
	// Check if ll + ml < cap(out)
	MOVQ 32(SP), AX
	MOVQ 24(SP), CX
	ADDQ 16(SP), CX
	CMPQ CX, AX
	JA   error_out_of_capacity

	// Copy literals
	MOVQ  24(SP), AX
	TESTQ AX, AX
	JZ    check_offset
	MOVQ  48(SP), CX
	MOVQ  40(SP), R10
	XORQ  R11, R11
	TESTQ $0x00000001, AX
	JZ    copy_1_word
	MOVB  (CX)(R11*1), R12
	MOVB  R12, (R10)(R11*1)
	ADDQ  $0x01, R11

copy_1_word:
	TESTQ $0x00000002, AX
	JZ    copy_1_dword
	MOVW  (CX)(R11*1), R12
	MOVW  R12, (R10)(R11*1)
	ADDQ  $0x02, R11

copy_1_dword:
	TESTQ $0x00000004, AX
	JZ    copy_1_qword
	MOVL  (CX)(R11*1), R12
	MOVL  R12, (R10)(R11*1)
	ADDQ  $0x04, R11

copy_1_qword:
	TESTQ $0x00000008, AX
	JZ    copy_1_test
	MOVQ  (CX)(R11*1), R12
	MOVQ  R12, (R10)(R11*1)
	ADDQ  $0x08, R11
	JMP   copy_1_test

copy_1:
	MOVUPS (CX)(R11*1), X0
	MOVUPS X0, (R10)(R11*1)
	ADDQ   $0x10, R11

copy_1_test:
	CMPQ R11, AX
	JB   copy_1
	ADDQ AX, 48(SP)
	ADDQ AX, 40(SP)
	ADDQ AX, 56(SP)
	MOVQ 8(SP), R12

	// Malformed input if seq.mo > t+len(hist) || seq.mo > s.windowSize)
check_offset:
	MOVQ 56(SP), AX
	ADDQ 64(SP), AX
	CMPQ R12, AX
	JG   error_match_off_too_big
	CMPQ R12, 80(SP)
	JG   error_match_off_too_big
	MOVQ 16(SP), AX

	// Copy match from history
	MOVQ  R12, CX
	SUBQ  56(SP), CX
	JLS   copy_match
	MOVQ  72(SP), R10
	SUBQ  CX, R10
	CMPQ  AX, CX
	JGE   copy_all_from_history
	MOVQ  40(SP), CX
	XORQ  R11, R11
	TESTQ $0x00000001, AX
	JZ    copy_4_word
	MOVB  (R10)(R11*1), R13
	MOVB  R13, (CX)(R11*1)
	ADDQ  $0x01, R11

copy_4_word:
	TESTQ $0x00000002, AX
	JZ    copy_4_dword
	MOVW  (R10)(R11*1), R13
	MOVW  R13, (CX)(R11*1)
	ADDQ  $0x02, R11

copy_4_dword:
	TESTQ $0x00000004, AX
	JZ    copy_4_qword
	MOVL  (R10)(R11*1), R13
	MOVL  R13, (CX)(R11*1)
	ADDQ  $0x04, R11

copy_4_qword:
	TESTQ $0x00000008, AX
	JZ    copy_4_test
	MOVQ  (R10)(R11*1), R13
	MOVQ  R13, (CX)(R11*1)
	ADDQ  $0x08, R11
	JMP   copy_4_test

copy_4:
	MOVUPS (R10)(R11*1), X0
	MOVUPS X0, (CX)(R11*1)
	ADDQ   $0x10, R11

copy_4_test:
	CMPQ R11, AX
	JB   copy_4
	ADDQ AX, 56(SP)
	ADDQ AX, 40(SP)
	JMP  handle_loop
	JMP loop_finished

copy_all_from_history:
	MOVQ  40(SP), R11
	XORQ  R13, R13
	TESTQ $0x00000001, CX
	JZ    copy_5_word
	MOVB  (R10)(R13*1), R14
	MOVB  R14, (R11)(R13*1)
	ADDQ  $0x01, R13

copy_5_word:
	TESTQ $0x00000002, CX
	JZ    copy_5_dword
	MOVW  (R10)(R13*1), R14
	MOVW  R14, (R11)(R13*1)
	ADDQ  $0x02, R13

copy_5_dword:
	TESTQ $0x00000004, CX
	JZ    copy_5_qword
	MOVL  (R10)(R13*1), R14
	MOVL  R14, (R11)(R13*1)
	ADDQ  $0x04, R13

copy_5_qword:
	TESTQ $0x00000008, CX
	JZ    copy_5_test
	MOVQ  (R10)(R13*1), R14
	MOVQ  R14, (R11)(R13*1)
	ADDQ  $0x08, R13
	JMP   copy_5_test

copy_5:
	MOVUPS (R10)(R13*1), X0
	MOVUPS X0, (R11)(R13*1)
	ADDQ   $0x10, R13

copy_5_test:
	CMPQ R13, CX
	JB   copy_5
	ADDQ CX, 40(SP)
	ADDQ CX, 56(SP)
	SUBQ CX, AX

	// Copy match from the current buffer
copy_match:
	TESTQ AX, AX
	JZ    handle_loop
	MOVQ  40(SP), CX
	SUBQ  R12, CX

	// ml <= mo
	CMPQ AX, R12
	JA   copy_overlapping_match

	// Copy non-overlapping match
	MOVQ 40(SP), R10
	XORQ R11, R11

copy_2:
	MOVUPS (CX)(R11*1), X0
	MOVUPS X0, (R10)(R11*1)
	ADDQ   $0x10, R11
	CMPQ   R11, AX
	JB     copy_2
	ADDQ   AX, 40(SP)
	ADDQ   AX, 56(SP)
	JMP    handle_loop

	// Copy overlapping match
copy_overlapping_match:
	MOVQ 40(SP), R10
	XORQ R11, R11

copy_slow_3:
	MOVB (CX)(R11*1), R13
	MOVB R13, (R10)(R11*1)
	INCQ R11
	CMPQ R11, AX
	JB   copy_slow_3
	ADDQ AX, 40(SP)
	ADDQ AX, 56(SP)

handle_loop:
	MOVQ ctx+16(FP), AX
	DECQ 96(AX)
	JNS  sequenceDecs_decodeSync_amd64_main_loop

loop_finished:
	MOVQ s+0(FP), AX
	MOVQ br+8(FP), AX
	MOVQ DX, 32(AX)
	MOVB BL, 40(AX)
	MOVQ SI, 24(AX)

	// Return success
	MOVQ $0x00000000, ret+24(FP)
	RET

	// Return with match length error
sequenceDecs_decodeSync_amd64_error_match_len_ofs_mismatch:
	MOVQ 16(SP), AX
	MOVQ ctx+16(FP), CX
	MOVQ AX, 224(CX)
	MOVQ $0x00000001, ret+24(FP)
	RET

	// Return with match too long error
sequenceDecs_decodeSync_amd64_error_match_len_too_big:
	MOVQ 16(SP), AX
	MOVQ ctx+16(FP), CX
	MOVQ AX, 224(CX)
	MOVQ $0x00000002, ret+24(FP)
	RET

	// Return with match offset too long error
error_match_off_too_big:
	MOVQ ctx+16(FP), AX
	MOVQ 8(SP), CX
	MOVQ CX, 232(AX)
	MOVQ 56(SP), CX
	MOVQ CX, 136(AX)
	MOVQ $0x00000003, ret+24(FP)
	RET

	// Return request to resize `out` by at least ll + ml bytes
error_out_of_capacity:
	MOVQ ctx+16(FP), AX
	MOVQ 24(SP), CX
	MOVQ CX, 216(AX)
	MOVQ 16(SP), CX
	MOVQ CX, 224(AX)
	MOVQ 56(SP), CX
	MOVQ CX, 136(AX)
	MOVQ br+8(FP), AX
	MOVQ DX, 32(AX)
	MOVB BL, 40(AX)
	MOVQ SI, 24(AX)
	MOVQ $0x00000004, ret+24(FP)
	RET
